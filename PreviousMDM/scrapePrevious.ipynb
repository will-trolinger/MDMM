{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metropolitan Statistical Area 2019Rank 2020Rank 2021Rank\n",
      "0                       Midland,TX        1       38        6\n",
      "1    SanJoseSunnyvaleSantaClara,CA        2        1        1\n",
      "2                     ProvoOrem,UT        3        5        9\n",
      "3                       Boulder,CO        4        9        7\n",
      "4    SanFranciscoOaklandHayward,CA        5      NaN      NaN\n",
      "..                             ...      ...      ...      ...\n",
      "418                   Fairbanks,AK      NaN      313      371\n",
      "419                   Anchorage,AK      NaN      326      350\n",
      "420          KingsportBristol,TNVA      NaN      351      240\n",
      "421             CapeGirardeau,MOIL      NaN      NaN         \n",
      "422                 St.Joseph,MOKS      NaN      NaN         \n",
      "\n",
      "[423 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import requests\n",
    "\n",
    "# URLs of the PDF files\n",
    "urls = [\n",
    "    'https://heartlandforward.org/wp-content/uploads/2020/12/Most-Dynamic-Metros.pdf',\n",
    "    'https://heartlandforward.org/wp-content/uploads/2022/04/Most-Dynamic-Metros_9.pdf',\n",
    "    'https://heartlandforward.org/wp-content/uploads/2023/03/MostDyanmicMetros2022.pdf'\n",
    "]\n",
    "\n",
    "# Pages to extract for each PDF\n",
    "pages_list = [range(134, 149), range(23, 34), range(31, 41)]\n",
    "\n",
    "# Starting year\n",
    "year = 2019\n",
    "\n",
    "# Initialize an empty DataFrame for the final merged result\n",
    "final_merged_df = None\n",
    "\n",
    "# Loop through each URL and corresponding page ranges\n",
    "for url, pages in zip(urls, pages_list):\n",
    "    # Send a GET request to fetch the content of the PDF\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Save the PDF locally\n",
    "    with open('Most-Dynamic-Metros.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Open the PDF and extract tables\n",
    "    with pdfplumber.open('Most-Dynamic-Metros.pdf') as pdf:\n",
    "        all_tables = []\n",
    "        for page_num in pages:\n",
    "            page = pdf.pages[page_num - 1]\n",
    "            page_tables = page.extract_tables()\n",
    "            for table in page_tables:\n",
    "                # Convert each table to a DataFrame\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                all_tables.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    year_df = pd.concat(all_tables, ignore_index=True)\n",
    "\n",
    "    # Data cleaning\n",
    "    year_df = year_df.replace('\\n', ' ', regex=True)\n",
    "    year_df = year_df.replace(' ', '', regex=True)\n",
    "    year_df = year_df.replace('-', '', regex=True)\n",
    "    year_df = year_df.iloc[:, :2].rename(columns={'': 'Metropolitan Statistical Area', 'Overall\\nRanking': f'{year}Rank',\n",
    "                                                  'OVERALL\\nRANKING': f'{year}Rank'})\n",
    "\n",
    "    # Merge with the final DataFrame\n",
    "    if final_merged_df is None:\n",
    "        final_merged_df = year_df\n",
    "    else:\n",
    "        final_merged_df = pd.merge(final_merged_df, year_df, on='Metropolitan Statistical Area', how='outer')\n",
    "\n",
    "    # Increment year\n",
    "    year += 1\n",
    "\n",
    "# Output the final merged DataFrame\n",
    "print(final_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_state(metro_name):\n",
    "    \"\"\"Extract the state abbreviation from a metro name.\"\"\"\n",
    "    return metro_name.split(',')[-1].strip() if ',' in metro_name else None\n",
    "\n",
    "def have_common_substring(str1, str2, min_length=5):\n",
    "    \"\"\"Check if two strings share a common significant substring.\"\"\"\n",
    "    for i in range(len(str1)):\n",
    "        for j in range(min_length, len(str1) - i + 1):\n",
    "            substring = str1[i:i+j]\n",
    "            if substring in str2 and len(substring) >= min_length and len(substring)/len(str2) > 0.5:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './Most-Dynamic-Metros.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Identify columns that contain the ranks\n",
    "rank_columns = [col for col in df.columns if 'Rank' in col]\n",
    "\n",
    "# Add a column to mark matched rows\n",
    "df['Matched'] = False\n",
    "\n",
    "# Iterate over the DataFrame to find matches\n",
    "for i, row1 in df.iterrows():\n",
    "    for j, row2 in df.iterrows():\n",
    "        if i != j:\n",
    "            # Check for common substring and same state\n",
    "            if have_common_substring(row1['Metropolitan Statistical Area'], row2['Metropolitan Statistical Area']) \\\n",
    "               and extract_state(row1['Metropolitan Statistical Area']) == extract_state(row2['Metropolitan Statistical Area']):\n",
    "                # Fill in missing ranks and mark as matched\n",
    "                is_filled = False\n",
    "                for col in rank_columns:\n",
    "                    if pd.isna(row1[col]) and not pd.isna(row2[col]):\n",
    "                        df.at[i, col] = row2[col]\n",
    "                        is_filled = True\n",
    "                if is_filled:\n",
    "                    df.at[j, 'Matched'] = True\n",
    "\n",
    "# Remove marked duplicate rows\n",
    "df = df[~df['Matched']]\n",
    "\n",
    "# Drop the 'Matched' column as it's no longer needed\n",
    "df.drop(columns=['Matched'], inplace=True)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('./Updated-Most-Dynamic-Metros.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Metropolitan Statistical Area Closest Match\n",
      "0                     Midland,TX          None\n",
      "1  SanJoseSunnyvaleSantaClara,CA          None\n",
      "2                   ProvoOrem,UT          None\n",
      "3                     Boulder,CO          None\n",
      "4  SanFranciscoOaklandHayward,CA          None\n",
      "5             AustinRoundRock,TX          None\n",
      "6       SeattleTacomaBellevue,WA          None\n",
      "7                     Greeley,CO          None\n",
      "8  NaplesImmokaleeMarcoIsland,FL          None\n",
      "9                   St.George,UT          None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './Most-Dynamic-Metros.csv'\n",
    "metros_df = pd.read_csv(file_path)\n",
    "\n",
    "# Custom function to find the closest match with a different scorer and lower threshold\n",
    "def get_closest_match(x, list_strings, scorer=fuzz.partial_ratio, threshold=0):\n",
    "    if x in list_strings:  # Skip if the exact match is in the list\n",
    "        return None\n",
    "    best_match = process.extractOne(x, list_strings, scorer=scorer)\n",
    "    return best_match[0] if best_match and best_match[1] > threshold else None\n",
    "\n",
    "# List of unique strings for matching\n",
    "list_strings = df['Metropolitan Statistical Area'].unique()\n",
    "\n",
    "# Apply the matching function\n",
    "df['Closest Match'] = df['Metropolitan Statistical Area'].apply(lambda x: get_closest_match(x, list_strings))\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand the matches\n",
    "print(df[['Metropolitan Statistical Area', 'Closest Match']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Metropolitan Statistical Area'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Metropolitan Statistical Area'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m         final_df \u001b[38;5;241m=\u001b[39m year_df\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m         final_df \u001b[38;5;241m=\u001b[39m \u001b[43mfuzzy_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetropolitan Statistical Area\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetropolitan Statistical Area\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Save the final merged DataFrame\u001b[39;00m\n\u001b[1;32m     59\u001b[0m final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMost-Dynamic-Metros-Merged.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[70], line 12\u001b[0m, in \u001b[0;36mfuzzy_merge\u001b[0;34m(df1, df2, key1, key2, threshold, limit)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mFuzzy merges two DataFrames.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create a mapping from the key1 values to the best matching key2 values\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m mapping \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: process\u001b[38;5;241m.\u001b[39mextractOne(x, df2[key2], score_cutoff\u001b[38;5;241m=\u001b[39mthreshold))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Extract the matched key2 values and scores into separate columns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mapping\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Metropolitan Statistical Area'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import requests\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Define the fuzzy matching function\n",
    "def fuzzy_merge(df1, df2, key1, key2, threshold=90, limit=1):\n",
    "    \"\"\"\n",
    "    Fuzzy merges two DataFrames.\n",
    "    \"\"\"\n",
    "    # Create a mapping from the key1 values to the best matching key2 values\n",
    "    mapping = df1[key1].apply(lambda x: process.extractOne(x, df2[key2], score_cutoff=threshold))\n",
    "\n",
    "    # Extract the matched key2 values and scores into separate columns\n",
    "    df1['matched_key'] = mapping.apply(lambda x: x[0] if x else None)\n",
    "    df1['score'] = mapping.apply(lambda x: x[1] if x else None)\n",
    "\n",
    "    # Perform the merge using the new 'matched_key' column in df1 and key2 in df2\n",
    "    return pd.merge(df1, df2, left_on='matched_key', right_on=key2, how='left')\n",
    "\n",
    "# URLs and page ranges of the PDF files\n",
    "urls_pages = {\n",
    "    'https://heartlandforward.org/wp-content/uploads/2020/12/Most-Dynamic-Metros.pdf': range(134, 149),\n",
    "    'https://heartlandforward.org/wp-content/uploads/2022/04/Most-Dynamic-Metros_9.pdf': range(23, 34),\n",
    "    'https://heartlandforward.org/wp-content/uploads/2023/03/MostDyanmicMetros2022.pdf': range(31, 41)\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame for the final merged result\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Process each PDF\n",
    "for year, (url, pages) in enumerate(urls_pages.items(), start=2019):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open('Most-Dynamic-Metros.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    with pdfplumber.open('Most-Dynamic-Metros.pdf') as pdf:\n",
    "        all_tables = []\n",
    "        for page_num in pages:\n",
    "            page = pdf.pages[page_num - 1]\n",
    "            page_tables = page.extract_tables()\n",
    "            for table in page_tables:\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                all_tables.append(df)\n",
    "\n",
    "    year_df = pd.concat(all_tables, ignore_index=True)\n",
    "    year_df = year_df.replace('\\n', ' ', regex=True).replace(' ', '', regex=True).replace('-', '', regex=True)\n",
    "    year_df = year_df.iloc[:, :2].rename(columns={'': 'Metropolitan Statistical Area', 'Overall\\nRanking': f'{year}Rank', 'OVERALL\\nRANKING': f'{year}Rank'})\n",
    "\n",
    "    # Merge with the final DataFrame using fuzzy matching\n",
    "    if final_df.empty:\n",
    "        final_df = year_df\n",
    "    else:\n",
    "        final_df = fuzzy_merge(final_df, year_df, 'Metropolitan Statistical Area', 'Metropolitan Statistical Area')\n",
    "\n",
    "# Save the final merged DataFrame\n",
    "final_df.to_csv('Most-Dynamic-Metros-Merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import requests\n",
    "\n",
    "# URL of the PDF file\n",
    "url = 'https://heartlandforward.org/wp-content/uploads/2023/03/MostDyanmicMetros2022.pdf'\n",
    "\n",
    "# Send a GET request to fetch the content of the PDF\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Save the PDF locally\n",
    "with open('Most-Dynamic-Metros.pdf', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Specify the range of pages\n",
    "pages = range(31, 41)\n",
    "\n",
    "# Open the PDF and extract tables\n",
    "with pdfplumber.open('Most-Dynamic-Metros.pdf') as pdf:\n",
    "    all_tables = []\n",
    "    for page_num in pages:\n",
    "        page = pdf.pages[page_num - 1]\n",
    "        page_tables = page.extract_tables()\n",
    "        for table in page_tables:\n",
    "            # Convert each table to a DataFrame\n",
    "            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "            all_tables.append(df)\n",
    "\n",
    "final_df22 = pd.concat(all_tables, ignore_index=True)\n",
    "final_df22 = final_df22.replace('\\n', ' ', regex=True)\n",
    "final_df22 = final_df22.replace(' ', '', regex=True)\n",
    "final_df22 = final_df22.replace('-', '', regex=True)\n",
    "final_df22 = final_df22.iloc[:, :2].rename(columns={'': 'Metropolitan Statistical Area', 'OVERALL\\nRANKING': '2021Rank'})\n",
    "final_df22.to_csv('Most-Dynamic-Metros.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metropolitan Statistical Area</th>\n",
       "      <th>2021Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SanJoseSunnyvaleSantaClara,CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElkhartGoshen,IN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SanFranciscoOaklandBerkeley,CA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AustinRoundRockGeorgetown,TX</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheVillages,FL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Farmington,NM</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>BeaumontPortArthur,TX</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Enid,OK</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>CapeGirardeau,MOIL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>St.Joseph,MOKS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metropolitan Statistical Area 2021Rank\n",
       "0     SanJoseSunnyvaleSantaClara,CA        1\n",
       "1                  ElkhartGoshen,IN        2\n",
       "2    SanFranciscoOaklandBerkeley,CA        3\n",
       "3      AustinRoundRockGeorgetown,TX        4\n",
       "4                    TheVillages,FL        5\n",
       "..                              ...      ...\n",
       "379                   Farmington,NM      380\n",
       "380           BeaumontPortArthur,TX      381\n",
       "381                         Enid,OK      382\n",
       "382              CapeGirardeau,MOIL         \n",
       "383                  St.Joseph,MOKS         \n",
       "\n",
       "[384 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdms = pd.merge(final_df20, final_df21, on='Metropolitan Statistical Area', how='outer')\n",
    "mdms = pd.merge(mdms, final_df22, on='Metropolitan Statistical Area', how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdms.to_csv('Most-Dynamic-Metros.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
